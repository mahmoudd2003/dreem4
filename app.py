# app.py
# -*- coding: utf-8 -*-
"""
Streamlit app for generating Arabic dream-interpretation articles with People-first, methodology, and E-E-A-T.
Includes:
- Outline generation with enforced mandatory headings (H2/H3)
- People-first Summary (3 lines)
- Draft generation (with target length + methodology refs)
- Review/Improve
- Quality Report (heuristics + source/section flags)
- Quality Gate (LLM-based JSON)
- Meta/FAQ generation
- JSON-LD (Article + FAQPage + Author + reviewedBy)
- Balance Rewriter
- Human Touch
- Export DOCX/PDF with mandatory disclaimer
"""

import os
import json
import streamlit as st

from utils.openai_client import llm
from utils.quality_checks import quality_report
from utils.meta_generator import generate_meta_and_faq
from utils.exporters import to_docx, to_pdf
from utils.heading_tools import enforce_outline, default_required
from utils.enhanced_fix import ensure_disclaimer
from utils.text_cleanup import remove_filler_phrases
from utils.heading_tools import normalize_methodology_heading

PROMPTS_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "prompts")

def _read_prompt(name: str) -> str:
    path = os.path.join(PROMPTS_DIR, name)
    if not os.path.exists(path):
        raise FileNotFoundError(f"Ù…Ù„Ù Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {path}")
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def _format_prompt(tpl: str, **kwargs) -> str:
    try:
        return tpl.format(**kwargs)
    except Exception:
        addon = ["\n\n[Ø§Ù„Ù…Ø¹Ø·ÙŠØ§Øª]"]
        for k, v in kwargs.items():
            addon.append(f"[{k.upper()}]: {v}")
        return tpl + "\n" + "\n".join(addon)

def _download_bytes(path: str) -> bytes:
    with open(path, "rb") as f:
        return f.read()

def _init_state():
    defaults = {
        "outline": "",
        "draft": "",
        "reviewed": "",
        "meta_json": "",
        "humanized": "",
        "quality_gate_json": "",
        "balanced": "",
        "people_first": "",
        "cleaned": "",
        "expanded": "",
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

st.set_page_config(page_title="Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ù„Ø§Øª ØªÙØ³ÙŠØ± Ø§Ù„Ø£Ø­Ù„Ø§Ù…", page_icon="ğŸŒ™", layout="wide")
_init_state()

st.title("ğŸŒ“ Ù†Ø¸Ø§Ù… ÙƒØªØ§Ø¨Ø© Ù…Ù‚Ø§Ù„Ø§Øª ØªÙØ³ÙŠØ± Ø§Ù„Ø£Ø­Ù„Ø§Ù…")
st.caption("People-first + Ù…Ù†Ù‡Ø¬ÙŠØ© ÙˆØ§Ø¶Ø­Ø© + E-E-A-T | Python + Streamlit + OpenAI")

with st.sidebar:
    st.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    st.markdown("- ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù `.env` ÙŠØ­ÙˆÙŠ `OPENAI_API_KEY`.")
    st.markdown("- ÙŠÙ…ÙƒÙ† Ø¶Ø¨Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ø¨Ø± `LLM_MODEL` ÙÙŠ `.env`.")
    temp = st.slider("Temperature", 0.0, 1.2, 0.4, 0.05, help="Ø¯Ø±Ø¬Ø© Ø§Ù„ØªÙ†ÙˆØ¹ ÙÙŠ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬")
    max_tokens = st.number_input("Max tokens", min_value=200, max_value=4000, value=1800, step=50)
    st.divider()
    st.markdown("**Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨ØªØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:**")
    st.code(
        "prompts/outline.txt\n"
        "prompts/people_first_summary.txt\n"
        "prompts/draft.txt\n"
        "prompts/review.txt\n"
        "prompts/meta_faq.txt\n"
        "prompts/human_touch.txt\n"
        "prompts/quality_gate.txt\n"
        "prompts/consistency_check.txt\n"
        "prompts/balance_rewriter.txt",
        language="bash"
    )

    st.subheader("Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ© ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹")
    ibn_sirin_edition = st.text_input("Ø·Ø¨Ø¹Ø© Ø§Ø¨Ù† Ø³ÙŠØ±ÙŠÙ†", value="")
    ibn_sirin_page    = st.text_input("ØµÙØ­Ø© Ø§Ø¨Ù† Ø³ÙŠØ±ÙŠÙ†", value="")
    nabulsi_edition   = st.text_input("Ø·Ø¨Ø¹Ø© Ø§Ù„Ù†Ø§Ø¨Ù„Ø³ÙŠ", value="")
    nabulsi_page      = st.text_input("ØµÙØ­Ø© Ø§Ù„Ù†Ø§Ø¨Ù„Ø³ÙŠ", value="")
    psych_ref         = st.text_input("Ù…Ø±Ø¬Ø¹ Ù†ÙØ³ÙŠ (Ø¹Ù†ÙˆØ§Ù†/Ø³Ù†Ø©/ØµÙØ­Ø©)", value="")

    st.subheader("E-E-A-T")
    author_name = st.text_input("Ø§Ø³Ù… Ø§Ù„ÙƒØ§ØªØ¨ (Author)", value="")
    author_credentials = st.text_input("Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„ÙƒØ§ØªØ¨/Ù†Ø¨Ø°Ø© Ù‚ØµÙŠØ±Ø©", value="")
    reviewed_by = st.text_input("Ù…Ø±Ø§Ø¬ÙØ¹ Ù…Ù† Ù‚ÙØ¨Ù„ (Ø®Ø¨ÙŠØ±/Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", value="")
    last_updated = st.text_input("ØªØ§Ø±ÙŠØ® Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« (YYYY-MM-DD)", value="")

    st.subheader("Ø·ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù")
    target_words = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª (ØªÙ‚Ø±ÙŠØ¨ÙŠ)", 400, 2000, 1000, 50)

col1, col2 = st.columns([1,1])
with col1:
    symbol = st.text_input("ğŸ”£ Ø§Ù„Ø±Ù…Ø² (symbol)", key="inp_symbol", placeholder="Ù…Ø«Ø§Ù„: Ø§Ù„Ø°Ù‡Ø¨ØŒ Ø§Ù„Ù…Ø·Ø±ØŒ Ø§Ù„Ø¨Ø­Ø±")
    primary_kw = st.text_input("ğŸ”‘ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (primary_kw)", key="inp_pk", placeholder="Ù…Ø«Ø§Ù„: ØªÙØ³ÙŠØ± Ø­Ù„Ù… Ø§Ù„Ø°Ù‡Ø¨")
with col2:
    related_kws = st.text_area("ğŸ§© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© (related_kws)", key="inp_rk", placeholder="Ø§ÙØµÙ„ Ø¨ÙŠÙ†Ù‡Ø§ Ø¨ÙÙˆØ§ØµÙ„ØŒ Ù…Ø«Ø§Ù„: ØªÙØ³ÙŠØ± Ø­Ù„Ù… Ø§Ù„Ø°Ù‡Ø¨ Ù„Ù„Ø¹Ø²Ø¨Ø§Ø¡ØŒ Ø±Ø¤ÙŠØ© Ø§Ù„Ø°Ù‡Ø¨ Ù„Ù„Ù…ØªØ²ÙˆØ¬Ø©")

article_area = st.text_area("ğŸ“ Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù†Øµ/Ø§Ù„Ù…Ø³ÙˆØ¯Ø§Øª", value=st.session_state.get("draft", ""), height=300, key="article_area")

st.divider()

# Actions
b1, b2, b3, b4, b5, b6, b7, b8, b9, b10, b11, b12 = st.columns(12)
gen_outline = b1.button("ğŸ§± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø®Ø·Ø·")
do_pfs      = b2.button("ğŸ‘¥ People-first Summary")
gen_draft   = b3.button("ğŸ§¾ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø³ÙˆØ¯Ø©")
do_review   = b4.button("ğŸ§¹ Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªØ­Ø³ÙŠÙ†")
do_quality  = b5.button("ğŸ” Quality Report")
do_qgate    = b6.button("âœ… Quality Gate")
do_meta     = b7.button("ğŸ§­ Meta/FAQ (JSON)")
do_jsonld   = b8.button("ğŸ§¾ JSON-LD")
do_balance  = b9.button("âš–ï¸ Balance Rewriter")
do_human    = b10.button("ğŸ‘¤ Human Touch")
exp_docx    = b11.button("â¬‡ï¸ ØªØµØ¯ÙŠØ± DOCX")
exp_pdf     = b12.button("â¬‡ï¸ ØªØµØ¯ÙŠØ± PDF")


st.divider()
c1, c2 = st.columns(2)
do_clean  = c1.button("ğŸ§½ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø­Ø³Ù‘ÙŠ/Ø§Ù„Ù…Ø¬Ø§Ø²ÙŠ")
do_expand = c2.button("ğŸ§© ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª")


# Defensive guard
try:
    gen_outline; do_pfs; gen_draft; do_review; do_quality; do_qgate; do_meta; do_jsonld; do_balance; do_human; exp_docx; exp_pdf
except NameError:
    gen_outline = do_pfs = gen_draft = do_review = do_quality = do_qgate = do_meta = do_jsonld = do_balance = do_human = exp_docx = exp_pdf = False

# Generate Outline
if gen_outline:
    try:
        if not symbol or not primary_kw:
            st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ù…Ø² ÙˆØ§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©.")
        else:
            tpl = _read_prompt("outline.txt")
            prompt = _format_prompt(
                tpl,
                symbol=symbol,
                primary_kw=primary_kw,
                related_kws=related_kws,
                ibn_sirin_edition=ibn_sirin_edition,
                ibn_sirin_page=ibn_sirin_page,
                nabulsi_edition=nabulsi_edition,
                nabulsi_page=nabulsi_page,
                psych_ref=psych_ref,
            )
            outline = llm(prompt, temperature=temp, max_tokens=min(max_tokens, 1200)).strip()
            # Enforce required headings
            req_h2, req_h3 = default_required(symbol)
            outline = enforce_outline(outline, req_h2, req_h3)
            outline = normalize_methodology_heading(outline)
            st.session_state["outline"] = outline
            st.success("ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ù†Ø¬Ø§Ø­ (Ù…Ø¹ ÙØ±Ø¶ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©).")
            st.text_area("ğŸ“‹ Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ù†Ø§ØªØ¬", value=st.session_state["outline"], height=300, key="outline_area")
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø®Ø·Ø·: {e}")

# People-first Summary
if do_pfs:
    try:
        base = st.session_state.get("reviewed") or st.session_state.get("draft") or st.session_state.get("outline") or article_area
        if not base or not base.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø®Ù„Ø§ØµØ© People-first.")
        else:
            tpl = _read_prompt("people_first_summary.txt")
            prompt = _format_prompt(tpl, article=base)
            pfs = llm(prompt, temperature=0.2, max_tokens=180)
            st.session_state["people_first"] = pfs.strip()
            st.success("ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø®Ù„Ø§ØµØ© People-first.")
            st.text_area("ğŸ‘¥ Ø§Ù„Ø®Ù„Ø§ØµØ© (3 Ø£Ø³Ø·Ø±)", value=st.session_state["people_first"], height=120, key="pfs_area")
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø®Ù„Ø§ØµØ© People-first: {e}")

# Generate Draft
if gen_draft:
    try:
        outline_src = st.session_state.get("outline") or ""
        if not outline_src:
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø®Ø·Ø·. Ù‚Ù… Ø£ÙˆÙ„Ù‹Ø§ Ø¨ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø®Ø·Ø·.")
        else:
            tpl = _read_prompt("draft.txt")
            prompt = _format_prompt(
                tpl,
                outline=outline_src,
                people_first=st.session_state.get("people_first", ""),
                ibn_sirin_edition=ibn_sirin_edition,
                ibn_sirin_page=ibn_sirin_page,
                nabulsi_edition=nabulsi_edition,
                nabulsi_page=nabulsi_page,
                psych_ref=psych_ref,
                target_words=target_words,
            )
            draft = llm(prompt, temperature=temp, max_tokens=max_tokens).strip()
            st.session_state["draft"] = draft
            st.session_state["reviewed"] = ""
            st.success("ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø³ÙˆØ¯Ø©.")
            st.text_area("ğŸ§¾ Ø§Ù„Ù…Ø³ÙˆØ¯Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø©", value=st.session_state["draft"], height=400, key="draft_area")
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø³ÙˆØ¯Ø©: {e}")

# Review
if do_review:
    try:
        base_text = st.session_state.get("reviewed") or st.session_state.get("draft") or article_area
        if not base_text or not base_text.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©. Ø§Ù„ØµÙ‚ Ù†ØµÙ‹Ø§ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø£Ùˆ ÙˆÙ„Ù‘Ø¯ Ù…Ø³ÙˆØ¯Ø©.")
        else:
            tpl = _read_prompt("review.txt")
            prompt = _format_prompt(tpl, text=base_text)
            improved = llm(prompt, temperature=0.2, max_tokens=max_tokens).strip()
            st.session_state["reviewed"] = improved
            st.success("ØªÙ…Øª Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†.")
            st.text_area("âœ¨ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©", value=st.session_state["reviewed"], height=400, key="reviewed_area")
    except Exception as e:
        st.error(f"ÙØ´Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©: {e}")

# Quality Report (heuristics)
if do_quality:
    try:
        target = st.session_state.get("reviewed") or st.session_state.get("draft") or article_area
        if not target or not target.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©.")
        else:
            q = quality_report(target)
            st.json(q, expanded=False)
    except Exception as e:
        st.error(f"ÙØ´Ù„ ÙØ­Øµ Ø§Ù„Ø¬ÙˆØ¯Ø©: {e}")

# Quality Gate (LLM-based JSON Report)
if do_qgate:
    try:
        target = st.session_state.get("humanized") or st.session_state.get("balanced") or st.session_state.get("reviewed") or st.session_state.get("draft") or article_area
        if not target or not target.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„ÙØ­Øµ Quality Gate.")
        else:
            tpl = _read_prompt("quality_gate.txt")
            prompt = _format_prompt(tpl, text=target)
            raw = llm(prompt, temperature=0.1, max_tokens=700)
            try:
                data = json.loads(raw)
                st.session_state["quality_gate_json"] = json.dumps(data, ensure_ascii=False, indent=2)
                st.json(data, expanded=False)
            except Exception:
                st.session_state["quality_gate_json"] = raw
                st.code(raw, language="json")
            st.success("ØªÙ… ØªÙ†ÙÙŠØ° Quality Gate.")
            if st.session_state.get("quality_gate_json"):
                try:
                    _qgate_bytes = st.session_state["quality_gate_json"].encode("utf-8")
                    st.download_button("ğŸ’¾ ØªÙ†Ø²ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Quality Gate (JSON)", data=_qgate_bytes, file_name="quality_gate.json", mime="application/json")
                except Exception as _e:
                    st.info(f"ØªØ¹Ø°Ù‘Ø± ØªØ¬Ù‡ÙŠØ² Ù…Ù„Ù Ø§Ù„ØªÙ†Ø²ÙŠÙ„: {_e}")
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªÙ†ÙÙŠØ° Quality Gate: {e}")

# Meta / FAQ (JSON) + JSON-LD
if do_meta:
    try:
        article = st.session_state.get("humanized") or st.session_state.get("balanced") or st.session_state.get("reviewed") or st.session_state.get("draft") or article_area
        if not article or not primary_kw:
            st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªÙˆÙÙŠØ± Ù†Øµ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙˆØ§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©.")
        else:
            meta = generate_meta_and_faq(article, primary_kw)
            st.session_state["meta_json"] = json.dumps(meta, ensure_ascii=False, indent=2)
            st.code(st.session_state["meta_json"], language="json")
            if "_warning" in meta:
                st.info(meta["_warning"])
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Meta/FAQ: {e}")

# JSON-LD build
if do_jsonld:
    try:
        if not st.session_state.get("meta_json"):
            st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Meta/FAQ Ø£ÙˆÙ„Ù‹Ø§.")
        else:
            from utils.meta_generator import build_jsonld
            meta = json.loads(st.session_state["meta_json"])
            author = {"name": author_name, "credentials": author_credentials}
            reviewer = {"name": reviewed_by}
            article_text = st.session_state.get("humanized") or st.session_state.get("balanced") or st.session_state.get("reviewed") or st.session_state.get("draft") or ""
            schema = build_jsonld(article_text, meta, author, reviewer, last_updated)
            schema_json = json.dumps(schema, ensure_ascii=False, indent=2)
            st.code(schema_json, language="json")
            st.download_button("ØªØ­Ù…ÙŠÙ„ JSON-LD", data=schema_json.encode("utf-8"), file_name="article_schema.json", mime="application/ld+json")
    except Exception as e:
        st.error(f"ÙØ´Ù„ Ø¨Ù†Ø§Ø¡ JSON-LD: {e}")

# Balance Rewriter
if do_balance:
    try:
        base_text = st.session_state.get("reviewed") or st.session_state.get("draft") or article_area
        if not base_text or not base_text.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ§Ø²Ù†. Ø§Ù„ØµÙ‚ Ù†ØµÙ‹Ø§ Ø£Ùˆ ÙˆÙ„Ù‘Ø¯ Ù…Ø³ÙˆØ¯Ø© Ø«Ù… Ø±Ø§Ø¬Ø¹.")
        else:
            tpl = _read_prompt("balance_rewriter.txt")
            prompt = _format_prompt(tpl, text=base_text)
            balanced = llm(prompt, temperature=0.25, max_tokens=max_tokens).strip()
            st.session_state["balanced"] = balanced
            st.success("ØªÙ…Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„ØªØ±Ø§Ø« ÙˆØ§Ù„Ù…Ø¹Ø§ØµØ±.")
            st.text_area("âš–ï¸ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ§Ø²Ù†", value=st.session_state["balanced"], height=400, key="balanced_area")
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆØ§Ø²Ù†: {e}")

# Human Touch
if do_human:
    try:
        base_text = st.session_state.get("balanced") or st.session_state.get("reviewed") or st.session_state.get("draft") or article_area
        if not base_text or not base_text.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù„Ù…Ø³Ø© Ø§Ù„Ø¨Ø´Ø±ÙŠØ©. Ø§Ù„ØµÙ‚ Ù†ØµÙ‹Ø§ Ø£Ùˆ ÙˆÙ„Ù‘Ø¯ Ù…Ø³ÙˆØ¯Ø© Ø«Ù… Ø±Ø§Ø¬Ø¹.")
        else:
            tpl = _read_prompt("human_touch.txt")
            prompt = _format_prompt(tpl, text=base_text)
            humanized = llm(prompt, temperature=0.3, max_tokens=max_tokens).strip()
            st.session_state["humanized"] = humanized
            st.success("ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù„Ù…Ø³Ø© Ø§Ù„Ø¨Ø´Ø±ÙŠØ©.")
            st.text_area("ğŸ‘¤ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„Ù„Ù…Ø³Ø© Ø§Ù„Ø¨Ø´Ø±ÙŠØ©", value=st.session_state["humanized"], height=400, key="humanized_area")
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù„Ù…Ø³Ø© Ø§Ù„Ø¨Ø´Ø±ÙŠØ©: {e}")


# Clean sensory/metaphorical language
if do_clean:
    try:
        base = (
            st.session_state.get("humanized")
            or st.session_state.get("balanced")
            or st.session_state.get("reviewed")
            or st.session_state.get("draft")
            or article_area
        )
        if not base or not base.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„Ù„ØªÙ†Ø¸ÙŠÙ.")
        else:
            cleaned = remove_filler_phrases(base)
            st.session_state["cleaned"] = cleaned.strip()
            st.success("ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø³ÙŠØ©/Ø§Ù„Ù…Ø¬Ø§Ø²ÙŠØ©.")
            st.text_area("ğŸ§½ Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ", value=st.session_state["cleaned"], height=400, key="cleaned_area")
    except Exception as e:
        st.error(f"ÙØ´Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {e}")

# Expand "Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø¤Ø«Ø±Ø©" to cover missing money scenarios
if do_expand:
    try:
        base = (
            st.session_state.get("cleaned")
            or st.session_state.get("humanized")
            or st.session_state.get("balanced")
            or st.session_state.get("reviewed")
            or st.session_state.get("draft")
            or article_area
        )
        if not base or not base.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„ØªÙˆØ³ÙŠØ¹Ù‡.")
        else:
            tpl = _read_prompt("cases_expander.txt")
            prompt = _format_prompt(tpl, article=base)
            expanded = llm(prompt, temperature=0.25, max_tokens=max_tokens).strip()
            st.session_state["expanded"] = expanded
            st.success("ØªÙ… ØªÙˆØ³ÙŠØ¹ Ù‚Ø³Ù… Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø¤Ø«Ø±Ø©.")
            st.text_area("ğŸ§© Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª", value=st.session_state["expanded"], height=400, key="expanded_area")
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª: {e}")

# Export DOCX / PDF (with disclaimer)
if exp_docx or exp_pdf:
    try:
        final_text = st.session_state.get("humanized") or st.session_state.get("balanced") or st.session_state.get("reviewed") or st.session_state.get("draft") or article_area
        if not final_text or not final_text.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„Ù„ØªØµØ¯ÙŠØ±.")
        else:
            final_text = remove_filler_phrases(final_text)
            final_text = ensure_disclaimer(final_text)
            os.makedirs("exports", exist_ok=True)
            if exp_docx:
                docx_path = to_docx(final_text, "exports/article.docx")
                st.download_button("ØªØ­Ù…ÙŠÙ„ DOCX", data=_download_bytes(docx_path), file_name="article.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")
            if exp_pdf:
                pdf_path = to_pdf(final_text, "exports/article.pdf")
                st.download_button("ØªØ­Ù…ÙŠÙ„ PDF", data=_download_bytes(pdf_path), file_name="article.pdf", mime="application/pdf")
    except Exception as e:
        st.error(f"ÙØ´Ù„ Ø§Ù„ØªØµØ¯ÙŠØ±: {e}")

st.caption("Â© Ù†Ø¸Ø§Ù… ØªÙØ³ÙŠØ± Ø§Ù„Ø£Ø­Ù„Ø§Ù… â€” ØªÙˆÙ„ÙŠØ¯ Ù…Ø³Ø¤ÙˆÙ„ ÙˆÙ…ØªÙˆØ§Ø²Ù† (ØªØ±Ø§Ø«/Ø¹Ù„Ù… Ù†ÙØ³) | People-first | E-E-A-T")
